{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskRCNN():\n",
    "\n",
    "    def __init__(self, mode, config, model_dir):\n",
    "        assert mode in ['training', 'inference']\n",
    "        self.mode = mode\n",
    "        self.config = config\n",
    "        self.model_dir = model_dir\n",
    "        self.set_log_dir()\n",
    "        self.keras_model = self.build(mode=mode, config=config)\n",
    "\n",
    "    def build(self, mode, config):\n",
    "        assert mode in ['training', 'inference']\n",
    "\n",
    "        h, w = config.IMAGE_SHAPE[:2]\n",
    "        if h / 2**6 != int(h / 2**6) or w / 2**6 != int(w / 2**6):\n",
    "            raise Exception(\"Image size must be dividable by 2 at least 6 times \"\n",
    "                            \"to avoid fractions when downscaling and upscaling.\"\n",
    "                            \"For example, use 256, 320, 384, 448, 512, ... etc. \")\n",
    "\n",
    "        input_image = KL.Input(\n",
    "            shape=[None, None, config.IMAGE_SHAPE[2]], name=\"input_image\")\n",
    "        input_image_meta = KL.Input(shape=[config.IMAGE_META_SIZE],\n",
    "                                    name=\"input_image_meta\")\n",
    "\n",
    "        input_anchors = KL.Input(shape=[None, 4], name=\"input_anchors\")\n",
    "\n",
    "        if callable(config.BACKBONE):\n",
    "            _, C2, C3, C4, C5 = config.BACKBONE(input_image, stage5=True,\n",
    "                                                train_bn=config.TRAIN_BN)\n",
    "        else:\n",
    "            _, C2, C3, C4, C5 = resnet_graph(input_image, config.BACKBONE,\n",
    "                                             stage5=True, train_bn=config.TRAIN_BN)\n",
    "        P5 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c5p5')(C5)\n",
    "        P4 = KL.Add(name=\"fpn_p4add\")([\n",
    "            KL.UpSampling2D(size=(2, 2), name=\"fpn_p5upsampled\")(P5),\n",
    "            KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c4p4')(C4)])\n",
    "        P3 = KL.Add(name=\"fpn_p3add\")([\n",
    "            KL.UpSampling2D(size=(2, 2), name=\"fpn_p4upsampled\")(P4),\n",
    "            KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c3p3')(C3)])\n",
    "        P2 = KL.Add(name=\"fpn_p2add\")([\n",
    "            KL.UpSampling2D(size=(2, 2), name=\"fpn_p3upsampled\")(P3),\n",
    "            KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c2p2')(C2)])\n",
    "\n",
    "        P2 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=\"SAME\", name=\"fpn_p2\")(P2)\n",
    "        P3 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=\"SAME\", name=\"fpn_p3\")(P3)\n",
    "        P4 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=\"SAME\", name=\"fpn_p4\")(P4)\n",
    "        P5 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=\"SAME\", name=\"fpn_p5\")(P5)\n",
    "\n",
    "        P6 = KL.MaxPooling2D(pool_size=(1, 1), strides=2, name=\"fpn_p6\")(P5)\n",
    "\n",
    "        rpn_feature_maps = [P2, P3, P4, P5, P6]\n",
    "\n",
    "        anchors = input_anchors\n",
    "\n",
    "        rpn = build_rpn_model(config.RPN_ANCHOR_STRIDE,\n",
    "                              len(config.RPN_ANCHOR_RATIOS), config.TOP_DOWN_PYRAMID_SIZE)\n",
    "\n",
    "        layer_outputs = [] \n",
    "        for p in rpn_feature_maps:\n",
    "            layer_outputs.append(rpn([p]))\n",
    "\n",
    "        output_names = [\"rpn_class_logits\", \"rpn_class\", \"rpn_bbox\"]\n",
    "        outputs = list(zip(*layer_outputs))\n",
    "        outputs = [KL.Concatenate(axis=1, name=n)(list(o))\n",
    "                   for o, n in zip(outputs, output_names)]\n",
    "\n",
    "        rpn_class_logits, rpn_class, rpn_bbox = outputs\n",
    "\n",
    "        proposal_count = config.POST_NMS_ROIS_INFERENCE\n",
    "        rpn_rois = ProposalLayer(\n",
    "            proposal_count=proposal_count,\n",
    "            nms_threshold=config.RPN_NMS_THRESHOLD,\n",
    "            name=\"ROI\",\n",
    "            config=config)([rpn_class, rpn_bbox, anchors])\n",
    "        \n",
    "        model = KM.Model([input_image, input_image_meta, input_anchors], \n",
    "                         rpn_rois, \n",
    "                         name='mask_rcnn')\n",
    "\n",
    "        if config.GPU_COUNT > 1:\n",
    "            from mrcnn.parallel_model import ParallelModel\n",
    "            model = ParallelModel(model, config.GPU_COUNT)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProposalLayer(KE.Layer):\n",
    "    def __init__(self, proposal_count, nms_threshold, config=None, **kwargs):\n",
    "        super(ProposalLayer, self).__init__(**kwargs)\n",
    "        self.config = config\n",
    "        self.proposal_count = proposal_count\n",
    "        self.nms_threshold = nms_threshold\n",
    "\n",
    "    def call(self, inputs):\n",
    "        scores = inputs[0][:, :, 1]\n",
    "        deltas = inputs[1]\n",
    "        deltas = deltas * np.reshape(self.config.RPN_BBOX_STD_DEV, [1, 1, 4])\n",
    "        anchors = inputs[2]\n",
    "\n",
    "        pre_nms_limit = tf.minimum(self.config.PRE_NMS_LIMIT, tf.shape(anchors)[1])\n",
    "        ix = tf.nn.top_k(scores, pre_nms_limit, sorted=True,\n",
    "                         name=\"top_anchors\").indices\n",
    "        scores = utils.batch_slice([scores, ix], lambda x, y: tf.gather(x, y),\n",
    "                                   self.config.IMAGES_PER_GPU)\n",
    "        deltas = utils.batch_slice([deltas, ix], lambda x, y: tf.gather(x, y),\n",
    "                                   self.config.IMAGES_PER_GPU)\n",
    "        pre_nms_anchors = utils.batch_slice([anchors, ix], lambda a, x: tf.gather(a, x),\n",
    "                                    self.config.IMAGES_PER_GPU,\n",
    "                                    names=[\"pre_nms_anchors\"])\n",
    "\n",
    "        boxes = utils.batch_slice([pre_nms_anchors, deltas],\n",
    "                                  lambda x, y: apply_box_deltas_graph(x, y),\n",
    "                                  self.config.IMAGES_PER_GPU,\n",
    "                                  names=[\"refined_anchors\"])\n",
    "\n",
    "        window = np.array([0, 0, 1, 1], dtype=np.float32)\n",
    "        boxes = utils.batch_slice(boxes,\n",
    "                                  lambda x: clip_boxes_graph(x, window),\n",
    "                                  self.config.IMAGES_PER_GPU,\n",
    "                                  names=[\"refined_anchors_clipped\"])\n",
    "\n",
    "        def nms(boxes, scores):\n",
    "            indices = tf.image.non_max_suppression(\n",
    "                boxes, scores, self.proposal_count,\n",
    "                self.nms_threshold, name=\"rpn_non_max_suppression\")\n",
    "            proposals = tf.gather(boxes, indices)\n",
    "            # Pad if needed\n",
    "            padding = tf.maximum(self.proposal_count - tf.shape(proposals)[0], 0)\n",
    "            proposals = tf.pad(proposals, [(0, padding), (0, 0)])\n",
    "            return proposals\n",
    "        proposals = utils.batch_slice([boxes, scores], nms,\n",
    "                                      self.config.IMAGES_PER_GPU)\n",
    "\n",
    "        zeros = np.zeros(shape=(1, self.config.POST_NMS_ROIS_INFERENCE, 4), dtype=np.float32)\n",
    "        zeros[0, :4, :] = 1.0\n",
    "\n",
    "        proposals = KL.Multiply()([proposals, tf.convert_to_tensor(zeros)])\n",
    "\n",
    "        return proposals\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.proposal_count, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
